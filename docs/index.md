# Stimm Platform Documentation

Welcome to the official documentation for the **Stimm Platform**, a modular, real-time AI voice assistant platform built with Python (FastAPI) and Next.js.

This documentation covers everything you need to know to get started, understand the architecture, develop, and deploy your own voice agents.

## Quick Links

- [Getting Started](user-guide/installation.md) – Install and run Stimm locally.
- [Architecture](developer-guide/architecture-overview.md) – Understand the system design and data flow.
- [Guides](developer-guide/development.md) – Development, testing, and deployment guides.
- [API Reference](api/python.md) – Auto-generated API documentation from Python code.
- [Contributing](project/contributing.md) – How to contribute to the project.

## Features

- **Real-time Voice Interaction**: Low-latency voice conversations using WebRTC and WebSocket transports.
- **SIP Telephony Integration**: Connect incoming phone calls to AI agents via SIP protocol.
- **Modular AI Providers**: Support for multiple LLM, TTS, and STT providers.
- **Administrable RAG Configurations**: Create and manage multiple RAG configurations with different providers.
- **Agent Management**: Admin interface to configure and manage multiple agents.
- **Modern Frontend**: Responsive web interface built with Next.js 16 and Tailwind CSS.

## Getting Help

If you encounter any issues or have questions, please check the [GitHub repository](https://github.com/stimm/stimm)