# Stimm Platform Documentation

Welcome to the official documentation for the **Stimm Platform**, a modular, real-time AI voice assistant platform built with Python (FastAPI) and Next.js.

This documentation covers everything you need to know to get started, understand the architecture, develop, and deploy your own voice agents.

## Quick Links

- [**Installation**](getting-started/installation.md) – Step-by-step guide to install Stimm.
- [**Quick Start**](getting-started/quick-start.md) – Launch your first agent in minutes.
- [**Configuration**](getting-started/configuration.md) – Configure providers (LLM, TTS, STT).
- [**Web Interface**](usage/web-interface.md) – Manage agents and RAG via the UI.
- [**SIP Integration**](developer/sip-integration.md) – Connect incoming phone calls.
- [**Architecture**](developer/architecture-overview.md) – Understand the system design.
- [**API Reference**](api-reference/rest.md) – REST API endpoints and usage.
- [**Contributing**](contributors/contributing.md) – How to contribute to the project.

## Features

- **Real-time Voice Interaction**: Low-latency voice conversations using WebRTC and WebSocket transports.
- **SIP Telephony Integration**: Connect incoming phone calls to AI agents via SIP protocol.
- **Modular AI Providers**: Support for multiple LLM, TTS, and STT providers.
- **Administrable RAG Configurations**: Create and manage multiple RAG configurations with different providers.
- **Agent Management**: Admin interface to configure and manage multiple agents.
- **Modern Frontend**: Responsive web interface built with Next.js 16 and Tailwind CSS.

## Getting Help

If you encounter any issues or have questions, please check the [GitHub repository](https://github.com/stimm/stimm)
