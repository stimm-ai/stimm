<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>STT Transcription Interface</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
            padding: 20px;
        }

        .stt-container {
            background: white;
            border-radius: 20px;
            box-shadow: 0 20px 40px rgba(0, 0, 0, 0.1);
            width: 100%;
            max-width: 800px;
            height: 80vh;
            display: flex;
            flex-direction: column;
            overflow: hidden;
        }

        .stt-header {
            background: linear-gradient(135deg, #4f46e5, #7c3aed);
            color: white;
            padding: 20px;
            text-align: center;
        }

        .stt-header h1 {
            font-size: 1.5rem;
            font-weight: 600;
            margin-bottom: 5px;
        }

        .stt-header p {
            opacity: 0.9;
            font-size: 0.9rem;
        }

        .audio-section {
            padding: 20px;
            background: #f8fafc;
            border-bottom: 1px solid #e5e7eb;
        }

        .audio-player {
            display: flex;
            flex-direction: column;
            gap: 12px;
        }

        .audio-controls {
            display: flex;
            gap: 12px;
            align-items: center;
        }

        .play-button {
            background: #4f46e5;
            color: white;
            border: none;
            border-radius: 12px;
            padding: 12px 20px;
            cursor: pointer;
            font-size: 1rem;
            font-weight: 500;
            transition: all 0.2s ease;
            display: flex;
            align-items: center;
            gap: 8px;
        }

        .play-button:hover:not(:disabled) {
            background: #4338ca;
            transform: translateY(-1px);
        }

        .play-button:disabled {
            background: #9ca3af;
            cursor: not-allowed;
            transform: none;
        }

        .audio-info {
            font-size: 0.9rem;
            color: #6b7280;
        }

        .transcription-section {
            flex: 1;
            display: flex;
            flex-direction: column;
            padding: 20px;
            background: white;
        }

        .transcription-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 12px;
        }

        .transcription-header h2 {
            font-size: 1.2rem;
            color: #374151;
        }

        .status-indicator {
            display: flex;
            align-items: center;
            gap: 8px;
            font-size: 0.9rem;
            color: #6b7280;
        }

        .status-dot {
            width: 8px;
            height: 8px;
            border-radius: 50%;
            background: #9ca3af;
        }

        .status-dot.connected {
            background: #10b981;
            animation: pulse 2s infinite;
        }

        .status-dot.transcribing {
            background: #f59e0b;
            animation: pulse 1s infinite;
        }

        .transcription-output {
            flex: 1;
            border: 2px solid #e5e7eb;
            border-radius: 12px;
            padding: 16px;
            background: #f8fafc;
            font-size: 1rem;
            line-height: 1.5;
            resize: none;
            font-family: inherit;
            overflow-y: auto;
            transition: all 0.2s ease;
        }

        .transcription-output:focus {
            outline: none;
            border-color: #4f46e5;
            box-shadow: 0 0 0 3px rgba(79, 70, 229, 0.1);
        }

        .transcription-output.transcribing {
            border-color: #f59e0b;
            background: #fffbeb;
        }

        .transcription-stats {
            margin-top: 12px;
            font-size: 0.8rem;
            color: #6b7280;
            display: flex;
            gap: 16px;
        }

        @keyframes pulse {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.5; }
        }

        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(10px); }
            to { opacity: 1; transform: translateY(0); }
        }

        /* Scrollbar styling */
        .transcription-output::-webkit-scrollbar {
            width: 6px;
        }

        .transcription-output::-webkit-scrollbar-track {
            background: #f1f5f9;
        }

        .transcription-output::-webkit-scrollbar-thumb {
            background: #cbd5e1;
            border-radius: 3px;
        }

        .transcription-output::-webkit-scrollbar-thumb:hover {
            background: #94a3b8;
        }
    </style>
</head>
<body>
    <div class="stt-container">
        <div class="stt-header">
            <h1>STT Transcription Interface</h1>
            <p>Play audio and see real-time transcription from whisper-stt service</p>
        </div>

        <div class="audio-section">
            <div class="audio-player">
                <div class="agent-selection" style="margin-bottom: 15px;">
                    <label for="agentSelect" style="display: block; margin-bottom: 8px; font-weight: 500; color: #374151;">Select Agent:</label>
                    <select id="agentSelect" style="width: 100%; padding: 10px; border: 2px solid #e5e7eb; border-radius: 8px; font-size: 14px; background: white;">
                        <option value="">Loading agents...</option>
                    </select>
                    <div id="agentInfo" style="margin-top: 8px; font-size: 0.85rem; color: #6b7280;">
                        STT Provider: <span id="providerName">None</span>
                    </div>
                </div>
                <div class="audio-controls">
                    <button class="play-button" id="playButton">
                        <svg width="16" height="16" viewBox="0 0 24 24" fill="currentColor">
                            <path d="M8 5v14l11-7z"/>
                        </svg>
                        Play Audio
                    </button>
                    <audio id="audioPlayer" controls style="display: none;">
                        <source src="/stt/test-audio" type="audio/wav">
                        Your browser does not support the audio element.
                    </audio>
                </div>
                <div class="audio-info">
                    Test audio: Enregistrement.wav (French speech sample)
                    <br>
                    <span>Sync streaming: Backend streams audio with correct timing</span>
                </div>
            </div>
        </div>

        <div class="transcription-section">
            <div class="transcription-header">
                <h2>Transcription Output</h2>
                <div class="status-indicator">
                    <div class="status-dot" id="statusDot"></div>
                    <span id="statusText">Ready</span>
                </div>
            </div>
            <textarea 
                class="transcription-output" 
                id="transcriptionOutput" 
                readonly 
                placeholder="Transcription will appear here in real-time..."
            ></textarea>
            <div class="transcription-stats">
                <span id="wordCount">Words: 0</span>
                <span id="charCount">Characters: 0</span>
                <span id="transcriptionTime">Time: 0s</span>
            </div>
        </div>
    </div>

    <!-- Load shared agent selector -->
    <script src="/app-static/agent_selector.js"></script>
    
    <script>
        class STTInterface {
            constructor() {
                this.audioPlayer = document.getElementById('audioPlayer');
                this.playButton = document.getElementById('playButton');
                this.providerName = document.getElementById('providerName');
                this.transcriptionOutput = document.getElementById('transcriptionOutput');
                this.statusDot = document.getElementById('statusDot');
                this.statusText = document.getElementById('statusText');
                this.wordCount = document.getElementById('wordCount');
                this.charCount = document.getElementById('charCount');
                this.transcriptionTime = document.getElementById('transcriptionTime');
                
                this.websocket = null;
                this.isPlaying = false;
                this.isTranscribing = false;
                this.startTime = null;
                this.transcription = '';
                this.selectedAgentId = null;
                
                // Initialize shared agent selector
                this.agentSelector = new AgentSelector('agentSelect', (agent, agentId) => this.onAgentChange(agent, agentId));
                
                this.initializeEventListeners();
            }

            initializeEventListeners() {
                this.playButton.addEventListener('click', () => this.togglePlayback());
                this.audioPlayer.addEventListener('play', () => this.onAudioPlay());
                this.audioPlayer.addEventListener('pause', () => this.onAudioPause());
                this.audioPlayer.addEventListener('ended', () => this.onAudioEnd());
            }

            onAgentChange(agent, agentId) {
                this.selectedAgentId = agentId;
                if (agent) {
                    this.providerName.textContent = agent.stt_provider;
                } else {
                    this.providerName.textContent = 'None';
                }
                
                // Stop any ongoing transcription when changing agents
                if (this.isTranscribing) {
                    this.stopTranscription();
                }
            }

            async togglePlayback() {
                if (this.isPlaying) {
                    this.audioPlayer.pause();
                } else {
                    try {
                        await this.audioPlayer.play();
                    } catch (error) {
                        console.error('Failed to play audio:', error);
                        this.updateStatus('error', 'Failed to play audio');
                    }
                }
            }

            onAudioPlay() {
                this.isPlaying = true;
                this.playButton.innerHTML = `
                    <svg width="16" height="16" viewBox="0 0 24 24" fill="currentColor">
                        <path d="M6 19h4V5H6v14zm8-14v14h4V5h-4z"/>
                    </svg>
                    Pause
                `;
                this.startTranscription();
            }

            onAudioPause() {
                this.isPlaying = false;
                this.playButton.innerHTML = `
                    <svg width="16" height="16" viewBox="0 0 24 24" fill="currentColor">
                        <path d="M8 5v14l11-7z"/>
                    </svg>
                    Play Audio
                `;
                this.stopTranscription();
            }

            onAudioEnd() {
                this.isPlaying = false;
                this.playButton.innerHTML = `
                    <svg width="16" height="16" viewBox="0 0 24 24" fill="currentColor">
                        <path d="M8 5v14l11-7z"/>
                    </svg>
                    Play Audio
                `;
                // Don't stop transcription immediately - wait for backend to finish
                // The backend will send a completion message when done
                console.log('ðŸŽµ Audio ended, waiting for transcription to complete...');
                
                // Set a timeout to close the connection if no messages arrive
                this.audioEndTimeout = setTimeout(() => {
                    if (this.isTranscribing && this.websocket && this.websocket.readyState === WebSocket.OPEN) {
                        console.log('â° Audio end timeout reached, closing WebSocket');
                        this.stopTranscription();
                    }
                }, 5000); // 5 seconds timeout
            }

            async startTranscription() {
                this.transcription = '';
                this.transcriptionOutput.value = '';
                this.startTime = Date.now();
                this.isTranscribing = true;
                
                this.updateStatus('transcribing', 'Starting synchronized streaming...');
                this.transcriptionOutput.classList.add('transcribing');

                try {
                    this.startAudioCapture();
                } catch (error) {
                    console.error('Failed to start transcription:', error);
                    this.updateStatus('error', 'Failed to connect to STT service');
                    this.isTranscribing = false;
                    this.transcriptionOutput.classList.remove('transcribing');
                }
            }

            stopTranscription() {
                this.isTranscribing = false;
                this.transcriptionOutput.classList.remove('transcribing');
                
                // Clear the audio end timeout if it exists
                if (this.audioEndTimeout) {
                    clearTimeout(this.audioEndTimeout);
                    this.audioEndTimeout = null;
                }
                
                if (this.websocket) {
                    this.websocket.close();
                    this.websocket = null;
                }

                this.updateStats();
                this.updateStatus('ready', 'Ready');
            }


            handleTranscriptionMessage(message) {
                try {
                    const data = JSON.parse(message);
                    
                    if (data.completed) {
                        // Backend has finished streaming and processing
                        console.log('âœ… Backend streaming completed');
                        this.stopTranscription();
                        return;
                    }
                    
                    if (data.transcript && data.transcript.trim()) {
                        if (data.is_final) {
                            // For final transcripts, add to the accumulated transcription
                            this.transcription += data.transcript + ' ';
                            this.transcriptionOutput.value = this.transcription.trim();
                        } else {
                            // For intermediate transcripts, show accumulated + latest intermediate
                            const displayText = this.transcription.trim() + ' ' + data.transcript;
                            this.transcriptionOutput.value = displayText.trim();
                        }
                        
                        // Auto-scroll to bottom
                        this.transcriptionOutput.scrollTop = this.transcriptionOutput.scrollHeight;
                        
                        this.updateStats();
                    }
                    
                    if (data.error) {
                        console.error('STT error:', data.error);
                        this.updateStatus('error', `STT Error: ${data.error}`);
                    }
                    
                } catch (error) {
                    console.error('Failed to parse WebSocket message:', error);
                }
            }

            async startAudioCapture() {
                try {
                    console.log('ðŸŽµ Starting synchronized audio streaming...');
                    
                    // Use the new sync-stream endpoint that handles audio streaming on backend
                    const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
                    const wsUrl = `${protocol}//${window.location.host}/api/stt/sync-stream?agent_id=${this.selectedAgentId}`;
                    console.log('ðŸ”— Connecting to sync streaming endpoint:', wsUrl);
                    console.log('ðŸ¤– Using agent ID:', this.selectedAgentId);
                    
                    this.websocket = new WebSocket(wsUrl);
                    
                    this.websocket.onopen = () => {
                        console.log('âœ… Sync streaming WebSocket connected');
                        this.updateStatus('connected', 'Connected to sync streaming service');
                        
                        // Send start signal to begin backend audio streaming
                        this.websocket.send('start');
                        console.log('ðŸš€ Sent start signal to backend');
                    };
                    
                    this.websocket.onmessage = (event) => {
                        console.log('ðŸ“¨ Sync streaming message received:', event.data);
                        this.handleTranscriptionMessage(event.data);
                    };
                    
                    this.websocket.onerror = (error) => {
                        console.error('âŒ Sync streaming WebSocket error:', error);
                        this.updateStatus('error', 'Sync streaming connection failed');
                    };
                    
                    this.websocket.onclose = (event) => {
                        console.log('ðŸ”Œ Sync streaming WebSocket disconnected, code:', event.code, 'reason:', event.reason);
                        if (this.isTranscribing) {
                            this.updateStatus('ready', 'Streaming completed');
                        }
                    };
                    
                } catch (error) {
                    console.error('âŒ Failed to start synchronized streaming:', error);
                    this.updateStatus('error', 'Failed to start synchronized streaming');
                }
            }


            updateStatus(status, message) {
                this.statusDot.className = 'status-dot';
                this.statusText.textContent = message;
                
                switch (status) {
                    case 'ready':
                        this.statusDot.style.background = '#9ca3af';
                        break;
                    case 'connected':
                        this.statusDot.classList.add('connected');
                        break;
                    case 'transcribing':
                        this.statusDot.classList.add('transcribing');
                        break;
                    case 'error':
                        this.statusDot.style.background = '#ef4444';
                        break;
                }
            }

            updateStats() {
                const currentText = this.transcriptionOutput.value;
                const words = currentText.trim().split(/\s+/).filter(word => word.length > 0);
                const characters = currentText.replace(/\s/g, '').length;
                const elapsedTime = this.startTime ? Math.round((Date.now() - this.startTime) / 1000) : 0;
                
                this.wordCount.textContent = `Words: ${words.length}`;
                this.charCount.textContent = `Characters: ${characters}`;
                this.transcriptionTime.textContent = `Time: ${elapsedTime}s`;
            }
        }

        // Initialize the interface when the page loads
        document.addEventListener('DOMContentLoaded', () => {
            new STTInterface();
        });
    </script>
</body>
</html>