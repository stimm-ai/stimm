/**
 * AudioStreamer - Module partag√© pour le streaming audio en temps r√©el
 * 
 * Ce module centralise la logique de lecture audio pour les interfaces TTS et Voicebot
 * en √©liminant la duplication de code entre les deux interfaces.
 * 
 * Fonctionnalit√©s :
 * - Gestion unifi√©e d'AudioContext
 * - File d'attente audio avec lecture s√©quentielle
 * - D√©codage PCM et WAV
 * - Gestion d'erreurs avec m√©thodes alternatives
 * - Suivi de latence et m√©triques
 */

class AudioStreamer {
    /**
     * Cr√©e une instance d'AudioStreamer
     * @param {Object} options - Options de configuration
     * @param {number} options.sampleRate - Taux d'√©chantillonnage par d√©faut (utilise les constantes du fournisseur)
     * @param {string} options.encoding - Encodage audio par d√©faut (utilise les constantes du fournisseur)
     * @param {Function} options.onPlaybackStart - Callback d√©clench√© au d√©but de la lecture
     * @param {Function} options.onPlaybackEnd - Callback d√©clench√© √† la fin de la lecture
     * @param {Function} options.onError - Callback pour les erreurs de lecture
     */
    constructor(options = {}) {
        this.options = {
            sampleRate: 44100, // Valeur par d√©faut temporaire, sera remplac√©e par les constantes du fournisseur
            encoding: 'pcm_s16le', // Valeur par d√©faut temporaire
            onPlaybackStart: () => {},
            onPlaybackEnd: () => {},
            onError: () => {},
            ...options
        };

        // √âtat du streaming audio
        this.audioContext = null;
        this.audioQueue = [];
        this.isPlayingAudio = false;
        this.audioChunkCounter = 0;
        this.playbackStarted = false;
        this.firstAudioChunkReceived = false;

        // M√©triques de performance
        this.metrics = {
            firstChunkLatency: null,
            playbackStartLatency: null,
            totalChunksPlayed: 0,
            totalBytesPlayed: 0
        };

        this.initialize();
    }

    /**
     * Initialise l'AudioStreamer
     */
    async initialize() {
        console.log('üéµ AudioStreamer initialis√©');
        
        // Charger les constantes du fournisseur depuis l'API
        try {
            const response = await fetch('/api/provider-constants');
            if (response.ok) {
                const providerConstants = await response.json();
                this.providerConstants = providerConstants;
                console.log('‚úÖ Constantes du fournisseur charg√©es:', providerConstants);
            } else {
                console.warn('‚ö†Ô∏è Impossible de charger les constantes du fournisseur, utilisation des valeurs par d√©faut');
            }
        } catch (error) {
            console.warn('‚ö†Ô∏è Erreur lors du chargement des constantes du fournisseur:', error);
        }
    }

    /**
     * Ajoute un chunk audio √† la file d'attente
     * @param {ArrayBuffer|Blob} audioData - Donn√©es audio √† jouer
     * @param {Object} metadata - M√©tadonn√©es optionnelles (latence, etc.)
     */
    addAudioChunk(audioData, metadata = {}) {
        // Suivi du premier chunk pour la latence
        if (!this.firstAudioChunkReceived) {
            this.firstAudioChunkReceived = true;
            this.metrics.firstChunkLatency = metadata.latency || Date.now();
            console.log(`‚è±Ô∏è Premier chunk audio re√ßu apr√®s ${this.metrics.firstChunkLatency}ms`);
        }

        this.audioChunkCounter++;
        this.metrics.totalChunksPlayed++;
        
        if (audioData.byteLength) {
            this.metrics.totalBytesPlayed += audioData.byteLength;
        }

        console.log(`üéµ Chunk audio ${this.audioChunkCounter} ajout√©: ${audioData.byteLength || audioData.size} bytes`);

        // Ajouter √† la file d'attente
        this.audioQueue.push(audioData);

        // D√©marrer la lecture si pas d√©j√† en cours
        if (!this.isPlayingAudio) {
            this.playAudioQueue();
        }
    }

    /**
     * Lit tous les chunks audio dans la file d'attente
     */
    async playAudioQueue() {
        if (this.isPlayingAudio || this.audioQueue.length === 0) return;

        this.isPlayingAudio = true;

        // Suivi du d√©but de lecture
        if (!this.playbackStarted) {
            this.playbackStarted = true;
            this.metrics.playbackStartLatency = Date.now();
            this.options.onPlaybackStart();
            console.log('üéµ D√©but de la lecture audio');
        }

        // Initialiser l'AudioContext si n√©cessaire
        if (!this.audioContext) {
            this.audioContext = new (window.AudioContext || window.webkitAudioContext)();
            console.log('üéµ AudioContext initialis√©');
        }

        // Reprendre l'AudioContext si suspendu (requis par les navigateurs)
        if (this.audioContext.state === 'suspended') {
            await this.audioContext.resume();
            console.log('üéµ AudioContext repris');
        }

        // Lire tous les chunks dans la file d'attente
        while (this.audioQueue.length > 0) {
            const audioData = this.audioQueue.shift();

            try {
                console.log(`üéµ Lecture du chunk audio: ${audioData.byteLength || audioData.size} bytes`);
                await this.playAudioDirect(audioData);
            } catch (error) {
                console.error('‚ùå √âchec de lecture du chunk audio:', error);
                await this.tryAlternativePlayback(audioData);
            }
        }

        this.isPlayingAudio = false;
        this.options.onPlaybackEnd();
        console.log('üéµ Lecture audio termin√©e');
    }

    /**
     * M√©thode principale de lecture audio bas√©e sur la configuration
     * @param {ArrayBuffer|Blob} audioData - Donn√©es audio √† jouer
     */
    async playAudioDirect(audioData) {
        // Convertir en ArrayBuffer si c'est un Blob
        let arrayBuffer;
        if (audioData instanceof Blob) {
            arrayBuffer = await audioData.arrayBuffer();
        } else {
            arrayBuffer = audioData;
        }

        console.log(`üéµ Lecture audio: ${arrayBuffer.byteLength} bytes, encoding: ${this.options.encoding}, sampleRate: ${this.options.sampleRate}`);

        try {
            // Bas√© sur l'encoding configur√©
            if (this.options.encoding === 'pcm_s16le' || this.options.encoding === 'linear16') {
                // D√©coder comme PCM 16-bit little-endian
                const audioBuffer = this.audioContext.createBuffer(1, arrayBuffer.byteLength / 2, this.options.sampleRate);
                const channelData = audioBuffer.getChannelData(0);
                
                // Convertir Int16 en Float32
                const int16Array = new Int16Array(arrayBuffer);
                for (let i = 0; i < int16Array.length; i++) {
                    channelData[i] = int16Array[i] / 32768.0;
                }
                
                const source = this.audioContext.createBufferSource();
                source.buffer = audioBuffer;
                source.connect(this.audioContext.destination);
                
                await new Promise((resolve) => {
                    source.onended = () => {
                        console.log('üéµ Chunk PCM termin√©');
                        resolve();
                    };
                    source.start();
                    console.log('üéµ Chunk PCM d√©marr√©');
                });
                
            } else if (this.options.encoding === 'mp3') {
                // D√©coder comme MP3
                const audioBuffer = await this.audioContext.decodeAudioData(arrayBuffer);
                const source = this.audioContext.createBufferSource();
                source.buffer = audioBuffer;
                source.connect(this.audioContext.destination);
                
                await new Promise((resolve) => {
                    source.onended = () => {
                        console.log('üéµ Chunk MP3 termin√©');
                        resolve();
                    };
                    source.start();
                    console.log('üéµ Chunk MP3 d√©marr√©');
                });
                
            } else {
                // Fallback: d√©codage g√©n√©rique (pour WAV, etc.)
                const audioBuffer = await this.audioContext.decodeAudioData(arrayBuffer);
                const source = this.audioContext.createBufferSource();
                source.buffer = audioBuffer;
                source.connect(this.audioContext.destination);
                
                await new Promise((resolve) => {
                    source.onended = () => {
                        console.log('üéµ Chunk g√©n√©rique termin√©');
                        resolve();
                    };
                    source.start();
                    console.log('üéµ Chunk g√©n√©rique d√©marr√©');
                });
            }
            
        } catch (error) {
            console.log('üîÑ √âchec du d√©codage principal, essai en m√©thode alternative...');
            throw error; // Laisser la m√©thode alternative g√©rer
        }
    }

    /**
     * M√©thode alternative de lecture (d√©codage WAV)
     * @param {ArrayBuffer|Blob} audioData - Donn√©es audio √† jouer
     */
    async tryAlternativePlayback(audioData) {
        console.log('üîÑ Essai de m√©thode de lecture alternative...');
        try {
            // Convertir en ArrayBuffer si c'est un Blob
            let arrayBuffer;
            if (audioData instanceof Blob) {
                arrayBuffer = await audioData.arrayBuffer();
            } else {
                arrayBuffer = audioData;
            }
            
            // Essayer de d√©coder en WAV
            const audioBuffer = await this.audioContext.decodeAudioData(arrayBuffer);
            const source = this.audioContext.createBufferSource();
            source.buffer = audioBuffer;
            source.connect(this.audioContext.destination);
            
            await new Promise((resolve) => {
                source.onended = resolve;
                source.start();
            });
            
            console.log('‚úÖ Lecture alternative r√©ussie');
        } catch (error) {
            console.error('‚ùå Lecture alternative √©chou√©e:', error);
            this.options.onError(error);
        }
    }

    /**
     * Arr√™te la lecture audio et vide la file d'attente
     */
    stopPlayback() {
        console.log('üõë Arr√™t de la lecture audio');
        
        // Vider la file d'attente
        this.audioQueue = [];
        this.isPlayingAudio = false;
        
        // R√©initialiser l'√©tat
        this.firstAudioChunkReceived = false;
        this.audioChunkCounter = 0;
        this.playbackStarted = false;
        
        console.log('‚úÖ Lecture audio arr√™t√©e');
    }

    /**
     * Nettoie les ressources audio
     */
    cleanup() {
        this.stopPlayback();
        
        if (this.audioContext) {
            this.audioContext.close();
            this.audioContext = null;
            console.log('üßπ AudioContext ferm√©');
        }
        
        // R√©initialiser les m√©triques
        this.metrics = {
            firstChunkLatency: null,
            playbackStartLatency: null,
            totalChunksPlayed: 0,
            totalBytesPlayed: 0
        };
    }

    /**
     * Met √† jour la configuration de l'AudioStreamer
     * @param {Object} newConfig - Nouvelle configuration
     */
    updateConfig(newConfig) {
        this.options = {
            ...this.options,
            ...newConfig
        };
        
        // Si des constantes de fournisseur sont disponibles, les utiliser pour les valeurs par d√©faut
        if (this.providerConstants && newConfig.provider) {
            const providerType = newConfig.providerType || 'tts'; // 'tts' ou 'stt'
            const providerName = newConfig.provider;
            
            if (this.providerConstants[providerType] && this.providerConstants[providerType][providerName]) {
                const providerConfig = this.providerConstants[providerType][providerName];
                
                // Mettre √† jour les valeurs par d√©faut avec les constantes du fournisseur
                if (providerConfig.SAMPLE_RATE && !this.options.sampleRate) {
                    this.options.sampleRate = providerConfig.SAMPLE_RATE;
                }
                if (providerConfig.ENCODING && !this.options.encoding) {
                    this.options.encoding = providerConfig.ENCODING;
                }
                
                console.log(`üéµ Configuration mise √† jour avec les constantes de ${providerName}:`, {
                    sampleRate: this.options.sampleRate,
                    encoding: this.options.encoding
                });
            }
        }
        
        console.log('üéµ AudioStreamer configuration updated:', this.options);
    }

    /**
     * R√©cup√®re les m√©triques de performance
     * @returns {Object} M√©triques de performance
     */
    getMetrics() {
        return {
            ...this.metrics,
            currentQueueSize: this.audioQueue.length,
            isPlaying: this.isPlayingAudio,
            totalChunks: this.audioChunkCounter
        };
    }

    /**
     * V√©rifie si la lecture est en cours
     * @returns {boolean} True si en cours de lecture
     */
    isPlaying() {
        return this.isPlayingAudio;
    }

    /**
     * R√©cup√®re la taille de la file d'attente
     * @returns {number} Nombre de chunks en attente
     */
    getQueueSize() {
        return this.audioQueue.length;
    }
}

// Export pour usage module
if (typeof module !== 'undefined' && module.exports) {
    module.exports = AudioStreamer;
}

// Export global pour usage navigateur
window.AudioStreamer = AudioStreamer;