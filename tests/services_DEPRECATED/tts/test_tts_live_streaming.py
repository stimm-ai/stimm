"""
Test TTS Live Streaming (Agent-based version)

This test verifies that the TTS service can handle live streaming of
incrementally generated text using agent configurations from the database.
It can run with the default agent or a specific agent by ID or name.
"""

import asyncio
import os
import pytest
import time
import tempfile
import json
import argparse
import sys
import wave
import struct
from uuid import UUID
from services.tts.tts import TTSService
from services.shared_streaming import shared_streaming_manager
from services.agents_admin.agent_manager import get_agent_manager
from services.agents_admin.agent_service import AgentService

def create_progress_bar(current, total, width=20, prefix=""):
    """Create a simple text-based progress bar"""
    progress = int(width * current / total) if total > 0 else 0
    bar = "â–ˆ" * progress + "â–‘" * (width - progress)
    percentage = int(100 * current / total) if total > 0 else 0
    return f"{prefix} [{bar}] {percentage}%"

def get_agent_config(agent_id=None, agent_name=None):
    """Get agent configuration by ID or name."""
    agent_manager = get_agent_manager()
    
    if agent_id:
        try:
            return agent_manager.get_agent_config(UUID(agent_id))
        except Exception as e:
            print(f"âŒ Error getting agent by ID {agent_id}: {e}")
            sys.exit(1)
    elif agent_name:
        try:
            # Get the full agent response to get the ID
            agent_service = AgentService()
            agents = agent_service.list_agents(active_only=True)
            for agent in agents.agents:
                if agent.name == agent_name:
                    # Return both the agent response and the config
                    return agent, agent_manager.get_agent_config(agent.id)
            raise Exception(f"Agent with name '{agent_name}' not found")
        except Exception as e:
            print(f"âŒ Error getting agent by name '{agent_name}': {e}")
            sys.exit(1)
    else:
        # Use default agent
        return None, agent_manager.get_agent_config()

def list_available_agents():
    """List all available agents for selection."""
    agent_service = AgentService()
    agents = agent_service.list_agents(active_only=True)
    
    print("Available agents:")
    print("-" * 80)
    for agent in agents.agents:
        print(f"ID: {agent.id}")
        print(f"Name: {agent.name}")
        print(f"Description: {agent.description or 'No description'}")
        print(f"TTS Provider: {agent.tts_provider}")
        print(f"LLM Provider: {agent.llm_provider}")
        print(f"STT Provider: {agent.stt_provider}")
        print(f"Default: {'Yes' if agent.is_default else 'No'}")
        print("-" * 80)
    
def add_wav_header_to_chunk(raw_audio_data, sample_rate=22050, sample_width=2, channels=1):
    """Add WAV header to raw PCM audio data to make it playable."""
    # Calculate data size
    data_size = len(raw_audio_data)
    
    # WAV header structure
    # RIFF header
    riff_header = b'RIFF'
    file_size = data_size + 36  # 36 = header size minus RIFF header and file size
    riff_chunk = riff_header + struct.pack('<I', file_size) + b'WAVE'
    
    # fmt chunk
    fmt_header = b'fmt '
    fmt_chunk_size = 16
    audio_format = 1  # PCM
    byte_rate = sample_rate * channels * sample_width
    block_align = channels * sample_width
    bits_per_sample = sample_width * 8
    
    fmt_chunk = (fmt_header +
                struct.pack('<IHHIIHH', fmt_chunk_size, audio_format, channels, sample_rate,
                           byte_rate, block_align, bits_per_sample))
    
    # data chunk
    data_header = b'data'
    data_chunk = data_header + struct.pack('<I', data_size) + raw_audio_data
    
    # Combine all parts
    wav_data = riff_chunk + fmt_chunk + data_chunk
    return wav_data

def make_chunks_playable(chunks_dir):
    """Convert raw audio chunks to proper WAV files with headers."""
    chunk_files = sorted([f for f in os.listdir(chunks_dir) if f.startswith("chunk_") and f.endswith(".wav")])
    
    if not chunk_files:
        print("âš ï¸ No audio chunks found to convert")
        return False
    
    converted_count = 0
    for chunk_file in chunk_files:
        chunk_path = os.path.join(chunks_dir, chunk_file)
        
        try:
            # Read raw audio data
            with open(chunk_path, 'rb') as f:
                raw_audio_data = f.read()
            
            # Add WAV header
            wav_data = add_wav_header_to_chunk(raw_audio_data)
            
            # Write back with proper WAV header
            with open(chunk_path, 'wb') as f:
                f.write(wav_data)
            
            converted_count += 1
            
        except Exception as e:
            print(f"âŒ Error converting {chunk_file}: {e}")
    
    if converted_count > 0:
        print(f"ğŸµ Converted {converted_count} chunks to playable WAV format")
        return True
    else:
        print("âŒ Failed to convert any audio chunks")
        return False

def create_audio_playback_instructions(chunks_dir):
    """Create instructions for playing the audio files."""
    instructions_file = os.path.join(chunks_dir, "playback_instructions.txt")
    
    with open(instructions_file, 'w') as f:
        f.write("Audio Playback Instructions\n")
        f.write("=" * 40 + "\n\n")
        f.write("Individual chunks:\n")
        f.write("- Each chunk_*.wav file is a separate audio segment\n")
        f.write("- Files have proper WAV headers for easy playback\n")
        f.write("- Play them in order to hear the complete text\n\n")
        f.write("Recommended players:\n")
        f.write("- VLC Media Player (works best)\n")
        f.write("- Windows Media Player\n")
        f.write("- QuickTime (macOS)\n")
        f.write("- Audacity (for detailed analysis)\n\n")
        f.write("Note: Audio is saved as 22050 Hz, 16-bit, mono PCM\n")
    
    return instructions_file

@pytest.mark.asyncio
async def test_tts_live_streaming(agent_id=None, agent_name=None, tokens_per_chunk=2):
    """Test TTS live streaming with optional agent selection.
    
    Args:
        agent_id: Optional agent ID to use for testing
        agent_name: Optional agent name to use for testing
        tokens_per_chunk: Number of tokens to send per chunk (default: 2)
    """
    
    # Get agent configuration
    agent_response, agent_config = get_agent_config(agent_id, agent_name)
    
    # Initialize TTS service with the selected agent
    # Pass agent_id if we have a specific agent, otherwise use default
    actual_agent_id = agent_id if agent_id else (str(agent_response.id) if agent_response else None)
    tts_service = TTSService(agent_id=actual_agent_id)
    
    # Verify the provider matches the agent configuration
    current_provider = agent_config.tts_provider
    print(f"Testing with agent: {agent_config.tts_provider}")
    print(f"Agent TTS configuration: {agent_config.tts_config}")

    # Use the environment variable for the test text
    text = os.getenv("TTS_INTERFACE_TEXT", "Cette dÃ©monstration met en avant la diffusion en temps rÃ©el des jetons dâ€™un modÃ¨le de langage. Merci d'avoir Ã©coutÃ© ce texte. Ce test permer, grÃ¢ce Ã  des sliders de visualisation, de vÃ©rifier si la rÃ©ception de chunks auidio se fait bien en parrallÃ¨lle avec l'envoie des tokens issue du LLM. J'Ã©spÃ¨re que cela vous aidera. A bientÃ´t pour de nouvelles aventures. Et surtout prenez soin de vous. Au revoir.")

    #print text content string
    print(f"Test text : {text}")
    

    async def llm_token_generator(text, tokens_per_chunk=tokens_per_chunk):
        """Simulates LLM token streaming behavior"""
        words = text.split()
        total_chunks = (len(words) + tokens_per_chunk - 1) // tokens_per_chunk

        # Always yield at least one chunk, even if text is empty
        if len(words) == 0:
            yield ""
            return

        for i in range(0, len(words), tokens_per_chunk):
            chunk = " ".join(words[i:i + tokens_per_chunk]) + " "
            current_chunk = i // tokens_per_chunk + 1
            yield chunk
            # Simulate LLM generation delay (50-150ms per token)
            await asyncio.sleep(0.05 + (0.1 * (i % 3)))

    audio_chunks = []
    chunk_count = 0
    words = text.split()
    total_send_chunks = (len(words) + tokens_per_chunk - 1) // tokens_per_chunk  # ceiling division
    send_progress = 0
    # Create a shared counter for sending progress
    send_counter = 0
    text_gen = llm_token_generator(text, tokens_per_chunk=tokens_per_chunk)

    print("ğŸµ Starting LLM token streaming test...")
    print("ğŸ”„ LLM Sending | ğŸ”Š TTS Receiving")
    print("-" * 60)
    print(f"Text length: {len(words)} words, Tokens per chunk: {tokens_per_chunk}, Total chunks: {total_send_chunks}")

    # Use the same recording system as the web interface
    record_chunks = os.getenv('TTS_RECORD_CHUNKS', 'false').lower() == 'true'
    chunks_dir = os.getenv('TTS_CHUNKS_DIR', '/tmp/tts_chunks_web')
    
    # If recording is enabled, use a directory that's accessible from the host
    if record_chunks:
        # Use a directory within /app that maps to the host filesystem
        accessible_chunks_dir = '/app/services/tts/tests/audio_chunks'
        os.makedirs(accessible_chunks_dir, exist_ok=True)
        # Clear existing files for a new recording
        for file in os.listdir(accessible_chunks_dir):
            file_path = os.path.join(accessible_chunks_dir, file)
            if os.path.isfile(file_path):
                os.remove(file_path)
        chunks_dir = accessible_chunks_dir
        print(f"ğŸ“ Audio chunk recording ENABLED - saving to: {chunks_dir}")
        print(f"   Audio files are accessible from host at: src/services/tts/tests/audio_chunks/")
        print(f"   Set TTS_RECORD_CHUNKS=false to disable recording")
    else:
        # Fallback to temporary directory if recording is disabled
        chunks_dir = tempfile.mkdtemp(prefix="tts_chunks_")
        print(f"ğŸ“ Audio chunk recording DISABLED - using temporary directory: {chunks_dir}")
        print(f"   Set TTS_RECORD_CHUNKS=true to enable persistent recording")

    async def consume_stream():
        nonlocal chunk_count, send_progress, send_counter

        # Use the shared streaming manager like the web interface does
        session_id = "test_session"
        
        async def text_generator():
            async for chunk in text_gen:
                # Convert to standardized JSON format like the web interface
                payload = {
                    "text": chunk,
                    "try_trigger_generation": True,
                    "flush": False
                }
                yield json.dumps(payload)
            # Send final signal
            final_payload = {
                "text": "",
                "try_trigger_generation": True,
                "flush": True
            }
            yield json.dumps(final_payload)

        async for audio_chunk in shared_streaming_manager.stream_text_to_audio_no_websocket(
            text_generator(), tts_service, session_id
        ):
            audio_chunks.append(audio_chunk)
            chunk_count += 1
            
            # Save each chunk to a file for analysis using the same system as web interface
            chunk_filename = os.path.join(chunks_dir, f"chunk_{chunk_count:03d}.wav")
            with open(chunk_filename, 'wb') as f:
                f.write(audio_chunk)
            print(f"ğŸ’¾ Saved chunk {chunk_count} to {chunk_filename} ({len(audio_chunk)} bytes)")
            
            # Create a readable summary file with chunk information
            summary_file = os.path.join(chunks_dir, "chunks_summary.txt")
            with open(summary_file, 'w') as f:
                f.write("TTS Audio Chunks Summary\n")
                f.write("=" * 50 + "\n")
                f.write(f"Test Date: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"Agent: {agent_config.tts_provider}\n")
                f.write(f"Text: {text[:100]}...\n\n")
                f.write("Chunk Details:\n")
                f.write("-" * 30 + "\n")
                for i, chunk in enumerate(audio_chunks, 1):
                    f.write(f"Chunk {i:03d}: {len(chunk):,} bytes\n")
                f.write(f"\nTotal chunks: {len(audio_chunks)}\n")
                f.write(f"Total bytes: {sum(len(c) for c in audio_chunks):,}\n")
            
            # Update send_progress from the shared counter
            send_progress = shared_gen.get_count()

            # Show both progress bars on the same line
            send_bar = create_progress_bar(send_progress, total_send_chunks, prefix="ğŸ”„ LLM Sending")
            receive_bar = create_progress_bar(chunk_count, max(chunk_count + 5, total_send_chunks), prefix="ğŸ”Š TTS Receiving")
            print(f"\r{send_bar} | {receive_bar}", end="", flush=True)

    # Create a shared generator system to track progress
    class SharedGenerator:
        def __init__(self, generator):
            self.generator = generator
            self.counter = 0
            self.queue = asyncio.Queue()
            
        async def track_and_forward(self):
            async for chunk in self.generator:
                self.counter += 1
                await self.queue.put(chunk)
            await self.queue.put(None)
            
        async def get_generator(self):
            while True:
                chunk = await self.queue.get()
                if chunk is None:
                    break
                yield chunk
                
        def get_count(self):
            return self.counter

    # Create shared generator
    shared_gen = SharedGenerator(text_gen)
    
    # Track sending progress
    async def track_sending():
        await shared_gen.track_and_forward()

    # Run both tasks concurrently
    send_task = asyncio.create_task(track_sending())
    # Use the shared generator for the TTS stream
    text_gen = shared_gen.get_generator()

    # Timeout global de 15s to ensure both sending and receiving complete
    try:
        await asyncio.wait_for(consume_stream(), timeout=15)
    except asyncio.TimeoutError:
        print("\nâš ï¸ Timeout reached â€” stopping stream gracefully")
    finally:
        send_task.cancel()
        try:
            await send_task
        except asyncio.CancelledError:
            pass

    # Show final progress at 100%
    send_bar = create_progress_bar(total_send_chunks, total_send_chunks, prefix="ğŸ”„ LLM Sending")
    receive_bar = create_progress_bar(chunk_count, chunk_count, prefix="ğŸ”Š TTS Receiving")
    print(f"\r{send_bar} | {receive_bar}")

    # Verify both sending and receiving completed successfully
    # Use the actual counter from shared_gen instead of send_progress
    actual_send_count = shared_gen.get_count()
    sending_complete = (actual_send_count == total_send_chunks)
    receiving_complete = (chunk_count > 0)

    if audio_chunks and sending_complete and receiving_complete:
        total = sum(len(c) for c in audio_chunks)
        print(f"\nâœ… {len(audio_chunks)} chunks received, total {total:,} bytes")
        
        # Final summary message
        if record_chunks:
            # Convert chunks to playable WAV format
            if make_chunks_playable(chunks_dir):
                print(f"ğŸ”Š Audio chunks converted to playable WAV format")
            
            # Create playback instructions
            instructions_file = create_audio_playback_instructions(chunks_dir)
            summary_file = os.path.join(chunks_dir, "chunks_summary.txt")
            print(f"ğŸ“„ Readable summary saved to: {summary_file}")
            print(f"ğŸ“‹ Playback instructions: {instructions_file}")
            print(f"ï¿½ Audio chunks saved to: {chunks_dir}")
        else:
            print(f"ğŸ“ Audio chunks saved to temporary directory: {chunks_dir}")
            print(f"   Set TTS_RECORD_CHUNKS=true to enable persistent recording")
            
        assert sending_complete, f"Sending not complete: {send_progress}/{total_send_chunks}"
        assert receiving_complete, f"Receiving not complete: {chunk_count} chunks"
    else:
        print(f"\nâš ï¸ Test failed - Sending: {actual_send_count}/{total_send_chunks}, Receiving: {chunk_count} chunks")
        assert False, f"Streaming incomplete - Sending: {actual_send_count}/{total_send_chunks}, Receiving: {chunk_count} chunks"

@pytest.mark.asyncio
async def test_tts_service_initialization(agent_id=None, agent_name=None):
    """Verify that TTS service initializes properly with agent configuration"""
    # Get agent configuration
    agent_response, agent_config = get_agent_config(agent_id, agent_name)
    
    # Initialize TTS service with the selected agent
    # Pass agent_id if we have a specific agent, otherwise use default
    actual_agent_id = agent_id if agent_id else (str(agent_response.id) if agent_response else None)
    tts_service = TTSService(agent_id=actual_agent_id)
    assert tts_service.provider is not None
    
    current_provider = agent_config.tts_provider
    print(f"TTS service initialized with provider: {current_provider}")
    print(f"Agent TTS configuration: {agent_config.tts_config}")
    
    print("âœ… TTS service initialized successfully with agent configuration")

def parse_arguments():
    """Parse command line arguments."""
    parser = argparse.ArgumentParser(
        description="Test TTS Live Streaming with Agent Selection",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Environment Variables:
  TTS_RECORD_CHUNKS     - Set to 'true' to save audio chunks to files (default: false)
  TTS_CHUNKS_DIR        - Directory to save audio chunks (default: /tmp/tts_chunks_web)
  TTS_INTERFACE_TEXT    - Text to use for TTS synthesis (can be overridden with --text)

Examples:
  # Test with default agent
  python test_tts_live_streaming.py

  # Test with specific agent by name
  python test_tts_live_streaming.py --agent-name "whisper-groq-elevenlabs"

  # Test with specific agent by ID
  python test_tts_live_streaming.py --agent-id "87b5b8ca-027c-4f97-95e8-74f77d7c1ca8"

  # List available agents
  python test_tts_live_streaming.py --list-agents

  # Test with custom text
  python test_tts_live_streaming.py --text "Hello, this is a test"

  # Test with different chunk size
  python test_tts_live_streaming.py --tokens-per-chunk 5
        """
    )
    parser.add_argument("--agent-id", help="Test with specific agent ID")
    parser.add_argument("--agent-name", help="Test with specific agent name")
    parser.add_argument("--list-agents", action="store_true", help="List available agents and exit")
    parser.add_argument("--text", help="Custom text for TTS (overrides TTS_INTERFACE_TEXT env var)")
    parser.add_argument("--tokens-per-chunk", type=int, default=2, help="Number of tokens per chunk (default: 2)")
    return parser.parse_args()

async def main():
    """Main function to run the test with optional agent selection."""
    args = parse_arguments()
    
    if args.list_agents:
        list_available_agents()
        return
    
    # Override text if provided
    if args.text:
        os.environ["TTS_INTERFACE_TEXT"] = args.text
    
    print("ğŸµ Starting TTS Live Streaming Test")
    print("=" * 60)
    
    if args.agent_id:
        print(f"ğŸ”§ Using agent ID: {args.agent_id}")
    elif args.agent_name:
        print(f"ğŸ”§ Using agent name: {args.agent_name}")
    else:
        print("ğŸ”§ Using default agent")
    
    # Run service initialization test with selected agent
    await test_tts_service_initialization(args.agent_id, args.agent_name)
    
    # Run live streaming test with selected agent
    await test_tts_live_streaming(args.agent_id, args.agent_name, tokens_per_chunk=args.tokens_per_chunk)
    
    print("âœ… Live streaming tests passed!")

if __name__ == "__main__":
    asyncio.run(main())
